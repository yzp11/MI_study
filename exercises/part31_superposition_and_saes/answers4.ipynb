{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Callable, Literal\n",
    "import einops\n",
    "import numpy as np\n",
    "import torch as t\n",
    "from jaxtyping import Float\n",
    "from torch import Tensor, nn\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.nn import functional as F\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Make sure exercises are in the path\n",
    "chapter = r\"chapter1_transformer_interp\"\n",
    "exercises_dir = Path(f\"{os.getcwd().split(chapter)[0]}/{chapter}/exercises\").resolve()\n",
    "section_dir = exercises_dir / \"part31_superposition_and_saes\"\n",
    "if str(exercises_dir) not in sys.path: sys.path.append(str(exercises_dir))\n",
    "\n",
    "import part31_superposition_and_saes.utils as utils\n",
    "import part31_superposition_and_saes.tests as tests\n",
    "from plotly_utils import line, imshow\n",
    "\n",
    "device = t.device(\n",
    "    \"mps\" if t.backends.mps.is_available() else \"cuda\" if t.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "t.manual_seed(2)\n",
    "MAIN = __name__ == \"__main__\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_lr(step, steps):\n",
    "    return (1 - (step / steps))\n",
    "\n",
    "def constant_lr(*_):\n",
    "    return 1.0\n",
    "\n",
    "def cosine_decay_lr(step, steps):\n",
    "    return np.cos(0.5 * np.pi * step / (steps - 1))\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    # We optimize n_inst models in a single training loop to let us sweep over sparsity or importance\n",
    "    # curves efficiently. You should treat the number of instances `n_inst` like a batch dimension, \n",
    "    # but one which is built into our training setup. Ignore the latter 3 arguments for now, they'll\n",
    "    # return in later exercises.\n",
    "    n_inst: int\n",
    "    n_features: int = 5\n",
    "    d_hidden: int = 2\n",
    "    n_correlated_pairs: int = 0\n",
    "    n_anticorrelated_pairs: int = 0\n",
    "    feat_mag_distn: Literal[\"unif\", \"jump\"] = \"unif\"\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    W: Float[Tensor, \"inst d_hidden feats\"]\n",
    "    b_final: Float[Tensor, \"inst feats\"]\n",
    "\n",
    "    # Our linear map (for a single instance) is x -> ReLU(W.T @ W @ x + b_final)\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        cfg: Config,\n",
    "        feature_probability: float | Tensor = 0.01,\n",
    "        importance: float | Tensor = 1.0,\n",
    "        device=device,\n",
    "    ):\n",
    "        super(Model, self).__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        if isinstance(feature_probability, float):\n",
    "            feature_probability = t.tensor(feature_probability)\n",
    "        self.feature_probability = feature_probability.to(device).broadcast_to(\n",
    "            (cfg.n_inst, cfg.n_features)\n",
    "        )\n",
    "        if isinstance(importance, float):\n",
    "            importance = t.tensor(importance)\n",
    "        self.importance = importance.to(device).broadcast_to((cfg.n_inst, cfg.n_features))\n",
    "\n",
    "        self.W = nn.Parameter(\n",
    "            nn.init.xavier_normal_(t.empty((cfg.n_inst, cfg.d_hidden, cfg.n_features)))\n",
    "        )\n",
    "        self.b_final = nn.Parameter(t.zeros((cfg.n_inst, cfg.n_features)))\n",
    "        self.to(device)\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        features: Float[Tensor, \"... inst feats\"],\n",
    "    ) -> Float[Tensor, \"... inst feats\"]:\n",
    "        h = einops.einsum(self.W, features,\n",
    "            \"inst d_hidden feats,... inst feats ->... inst d_hidden\")\n",
    "        h1 = einops.einsum(self.W.transpose(1,2),h,\n",
    "            \"inst feats d_hidden,... inst d_hidden ->... inst feats\")\n",
    "        out = F.relu(h1 + self.b_final)\n",
    "        return out\n",
    "\n",
    "\n",
    "    def generate_batch(self, batch_size) -> Float[Tensor, \"batch inst feats\"]:\n",
    "        \"\"\"\n",
    "        Generates a batch of data.\n",
    "        \"\"\"\n",
    "        # You'll fill this in later\n",
    "\n",
    "        data_size = (batch_size, self.cfg.n_inst, self.cfg.n_features)\n",
    "        data = t.rand(data_size, device= self.W.device)\n",
    "        pro = t.rand(data_size, device= self.W.device)\n",
    "\n",
    "        return t.where(pro<self.feature_probability, data, 0.0)\n",
    "        \n",
    "\n",
    "\n",
    "    def calculate_loss(\n",
    "        self,\n",
    "        out: Float[Tensor, \"batch inst feats\"],\n",
    "        batch: Float[Tensor, \"batch inst feats\"],\n",
    "    ) -> Float[Tensor, \"\"]:\n",
    "        \"\"\"\n",
    "        Calculates the loss for a given batch (as a scalar tensor), using this loss described in the\n",
    "        Toy Models of Superposition paper:\n",
    "\n",
    "            https://transformer-circuits.pub/2022/toy_model/index.html#demonstrating-setup-loss\n",
    "\n",
    "        Note, `self.importance` is guaranteed to broadcast with the shape of `out` and `batch`.\n",
    "        \"\"\"\n",
    "        # You'll fill this in later\n",
    "        error = self.importance * ( (out-batch)**2 )\n",
    "        loss = einops.reduce(error,\n",
    "                             \"batch inst feats->inst\", \"mean\").sum()\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def optimize(\n",
    "        self,\n",
    "        batch_size: int = 1024,\n",
    "        steps: int = 10_000,\n",
    "        log_freq: int = 50,\n",
    "        lr: float = 1e-3,\n",
    "        lr_scale: Callable[[int, int], float] = constant_lr,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Optimizes the model using the given hyperparameters.\n",
    "        \"\"\"\n",
    "        optimizer = t.optim.Adam(list(self.parameters()), lr=lr)\n",
    "\n",
    "        progress_bar = tqdm(range(steps))\n",
    "\n",
    "        for step in progress_bar:\n",
    "            # Update learning rate\n",
    "            step_lr = lr * lr_scale(step, steps)\n",
    "            for group in optimizer.param_groups:\n",
    "                group[\"lr\"] = step_lr\n",
    "\n",
    "            # Optimize\n",
    "            optimizer.zero_grad()\n",
    "            batch = self.generate_batch(batch_size)\n",
    "            out = self(batch)\n",
    "            loss = self.calculate_loss(out, batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Display progress bar\n",
    "            if step % log_freq == 0 or (step + 1 == steps):\n",
    "                progress_bar.set_postfix(loss=loss.item() / self.cfg.n_inst, lr=step_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SAEConfig:\n",
    "    n_inst: int\n",
    "    d_in: int\n",
    "    d_sae: int\n",
    "    l1_coeff: float = 0.2\n",
    "    weight_normalize_eps: float = 1e-8\n",
    "    tied_weights: bool = False\n",
    "    architecture: Literal[\"standard\", \"gated\"] = \"standard\"\n",
    "\n",
    "\n",
    "class SAE(nn.Module):\n",
    "    W_enc: Float[Tensor, \"inst d_in d_sae\"]\n",
    "    _W_dec: Float[Tensor, \"inst d_sae d_in\"] | None\n",
    "    b_enc: Float[Tensor, \"inst d_sae\"]\n",
    "    b_dec: Float[Tensor, \"inst d_in\"]\n",
    "\n",
    "    def __init__(self, cfg: SAEConfig, model: Model) -> None:\n",
    "        super(SAE, self).__init__()\n",
    "\n",
    "        assert cfg.d_in == model.cfg.d_hidden, \"Model's hidden dim doesn't match SAE input dim\"\n",
    "        self.cfg = cfg\n",
    "        self.model = model.requires_grad_(False)\n",
    "\n",
    "        self.W_enc = nn.Parameter(\n",
    "            nn.init.kaiming_uniform_(t.empty((cfg.n_inst, cfg.d_in, cfg.d_sae)))\n",
    "        )\n",
    "        self._W_dec = (\n",
    "            None\n",
    "            if self.cfg.tied_weights\n",
    "            else nn.Parameter(nn.init.kaiming_uniform_(t.empty((cfg.n_inst, cfg.d_sae, cfg.d_in))))\n",
    "        )\n",
    "        self.b_enc = nn.Parameter(t.zeros(cfg.n_inst, cfg.d_sae))\n",
    "        self.b_dec = nn.Parameter(t.zeros(cfg.n_inst, cfg.d_in))\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    @property\n",
    "    def W_dec(self) -> Float[Tensor, \"inst d_sae d_in\"]:\n",
    "        return self._W_dec if self._W_dec is not None else self.W_enc.transpose(-1, -2)\n",
    "\n",
    "    @property\n",
    "    def W_dec_normalized(self) -> Float[Tensor, \"inst d_sae d_in\"]:\n",
    "        \"\"\"Returns decoder weights, normalized over the autoencoder input dimension.\"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        return self.W_dec / self.W_dec.norm(dim = -1, keepdim= True)\n",
    "\n",
    "    def generate_batch(self, batch_size: int) -> Float[Tensor, \"batch inst d_in\"]:\n",
    "        \"\"\"\n",
    "        Generates a batch of hidden activations from our model.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        data = self.model.generate_batch(batch_size= batch_size)\n",
    "        h = einops.einsum(self.model.W, data,\n",
    "            \"inst d_hidden feats,... inst feats ->... inst d_hidden\")\n",
    "        \n",
    "        return h\n",
    "\n",
    "    def forward(\n",
    "        self, h: Float[Tensor, \"batch inst d_in\"]\n",
    "    ) -> tuple[\n",
    "        dict[str, Float[Tensor, \"batch inst\"]],\n",
    "        Float[Tensor, \"\"],\n",
    "        Float[Tensor, \"batch inst d_sae\"],\n",
    "        Float[Tensor, \"batch inst d_in\"],\n",
    "    ]:\n",
    "        \"\"\"\n",
    "        Forward pass on the autoencoder.\n",
    "\n",
    "        Args:\n",
    "            h: hidden layer activations of model\n",
    "\n",
    "        Returns:\n",
    "            loss_dict: dict of different loss function term values, for every (batch elem, instance)\n",
    "            loss: scalar total loss (summed over instances & averaged over batch dim)\n",
    "            acts: autoencoder feature activations\n",
    "            h_reconstructed: reconstructed autoencoder input\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        z = F.relu(self.b_enc + \n",
    "                   einops.einsum(\n",
    "                       self.W_enc, h-self.b_dec,\n",
    "                       \"inst d_in d_sae, batch inst d_in -> batch inst d_sae\"\n",
    "                   ))\n",
    "        h_ = self.b_dec + einops.einsum(self.W_dec, z,\n",
    "                    \"inst d_sae d_in, batch inst d_sae -> batch inst d_in\")\n",
    "        \n",
    "        L_re = (h-h_).pow(2).mean(-1)\n",
    "        L_sp = z.abs().sum(-1)\n",
    "\n",
    "        loss_dict = {\n",
    "            \"L_reconstruction\": L_re,\n",
    "            \"L_sparsity\": L_sp,\n",
    "        }\n",
    "        loss = (L_re + L_sp* self.cfg.l1_coeff).mean(0).sum()\n",
    "\n",
    "        return loss_dict, loss, z, h_\n",
    "\n",
    "    def optimize(\n",
    "        self,\n",
    "        batch_size: int = 1024,\n",
    "        steps: int = 10_000,\n",
    "        log_freq: int = 50,\n",
    "        lr: float = 1e-3,\n",
    "        lr_scale: Callable[[int, int], float] = constant_lr,\n",
    "        resample_method: Literal[\"simple\", \"advanced\", None] = None,\n",
    "        resample_freq: int = 2500,\n",
    "        resample_window: int = 500,\n",
    "        resample_scale: float = 0.5,\n",
    "    ) -> dict[str, list]:\n",
    "        \"\"\"\n",
    "        Optimizes the autoencoder using the given hyperparameters.\n",
    "\n",
    "        Args:\n",
    "            model:              we reconstruct features from model's hidden activations\n",
    "            batch_size:         size of batches we pass through model & train autoencoder on\n",
    "            steps:              number of optimization steps\n",
    "            log_freq:           number of optimization steps between logging\n",
    "            lr:                 learning rate\n",
    "            lr_scale:           learning rate scaling function\n",
    "            resample_method:    method for resampling dead latents\n",
    "            resample_freq:      number of optimization steps between resampling dead latents\n",
    "            resample_window:    number of steps needed for us to classify a neuron as dead\n",
    "            resample_scale:     scale factor for resampled neurons\n",
    "\n",
    "        Returns:\n",
    "            data_log:               dictionary containing data we'll use for visualization\n",
    "        \"\"\"\n",
    "        assert resample_window <= resample_freq\n",
    "\n",
    "        optimizer = t.optim.Adam(list(self.parameters()), lr=lr, betas=(0.0, 0.999))\n",
    "        frac_active_list = []\n",
    "        progress_bar = tqdm(range(steps))\n",
    "\n",
    "        # Create lists to store data we'll eventually be plotting\n",
    "        data_log = {\"steps\": [], \"W_enc\": [], \"W_dec\": [], \"frac_active\": []}\n",
    "\n",
    "        for step in progress_bar:\n",
    "            # Resample dead latents\n",
    "            if (resample_method is not None) and ((step + 1) % resample_freq == 0):\n",
    "                frac_active_in_window = t.stack(frac_active_list[-resample_window:], dim=0)\n",
    "                if resample_method == \"simple\":\n",
    "                    self.resample_simple(frac_active_in_window, resample_scale)\n",
    "                elif resample_method == \"advanced\":\n",
    "                    self.resample_advanced(frac_active_in_window, resample_scale, batch_size)\n",
    "\n",
    "            # Update learning rate\n",
    "            step_lr = lr * lr_scale(step, steps)\n",
    "            for group in optimizer.param_groups:\n",
    "                group[\"lr\"] = step_lr\n",
    "\n",
    "            # Get a batch of hidden activations from the model\n",
    "            with t.inference_mode():\n",
    "                h = self.generate_batch(batch_size)\n",
    "\n",
    "            # Optimize\n",
    "            loss_dict, loss, acts, _ = self.forward(h)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Normalize decoder weights by modifying them inplace (if not using tied weights)\n",
    "            if not self.cfg.tied_weights:\n",
    "                self.W_dec.data = self.W_dec_normalized\n",
    "\n",
    "            # Calculate the mean sparsities over batch dim for each feature\n",
    "            frac_active = (acts.abs() > 1e-8).float().mean(0)\n",
    "            frac_active_list.append(frac_active)\n",
    "\n",
    "            # Display progress bar, and append new values for plotting\n",
    "            if step % log_freq == 0 or (step + 1 == steps):\n",
    "                progress_bar.set_postfix(\n",
    "                    lr=step_lr,\n",
    "                    frac_active=frac_active.mean().item(),\n",
    "                    **{k: v.mean(0).sum().item() for k, v in loss_dict.items()},  # type: ignore\n",
    "                )\n",
    "                data_log[\"W_enc\"].append(self.W_enc.detach().cpu().clone())\n",
    "                data_log[\"W_dec\"].append(self.W_dec.detach().cpu().clone())\n",
    "                data_log[\"frac_active\"].append(frac_active.detach().cpu().clone())\n",
    "                data_log[\"steps\"].append(step)\n",
    "\n",
    "        return data_log\n",
    "\n",
    "    @t.no_grad()\n",
    "    def resample_simple(\n",
    "        self,\n",
    "        frac_active_in_window: Float[Tensor, \"window inst d_sae\"],\n",
    "        resample_scale: float,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Resamples dead latents, by modifying the model's weights and biases inplace.\n",
    "\n",
    "        Resampling method is:\n",
    "            - For each dead neuron, generate a random vector of size (d_in,), and normalize these vectors\n",
    "            - Set new values of W_dec and W_enc to be these normalized vectors, at each dead neuron\n",
    "            - Set b_enc to be zero, at each dead neuron\n",
    "        \"\"\"\n",
    "        # Get a tensor of dead latents\n",
    "        dead_latents_mask = (frac_active_in_window < 1e-8).all(dim=0)  # [instances d_sae]\n",
    "        n_dead = int(dead_latents_mask.int().sum().item())\n",
    "\n",
    "        # Get our random replacement values of shape [n_dead d_in], and scale them\n",
    "        replacement_values = t.randn((n_dead, self.cfg.d_in), device=self.W_enc.device)\n",
    "        replacement_values_normed = replacement_values / (\n",
    "            replacement_values.norm(dim=-1, keepdim=True) + self.cfg.weight_normalize_eps\n",
    "        )\n",
    "\n",
    "        # Change the corresponding values in W_enc, W_dec, and b_enc\n",
    "        self.W_enc.data.transpose(-1, -2)[dead_latents_mask] = resample_scale * replacement_values_normed\n",
    "        self.W_dec.data[dead_latents_mask] = replacement_values_normed\n",
    "        self.b_enc.data[dead_latents_mask] = 0.0\n",
    "\n",
    "    @t.no_grad()\n",
    "    def resample_advanced(\n",
    "        self,\n",
    "        frac_active_in_window: Float[Tensor, \"window inst d_sae\"],\n",
    "        resample_scale: float,\n",
    "        batch_size: int,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Resamples latents that have been dead for 'dead_feature_window' steps, according to `frac_active`.\n",
    "\n",
    "        Resampling method is:\n",
    "            - Compute the L2 reconstruction loss produced from the hidden state vectors `h`\n",
    "            - Randomly choose values of `h` with probability proportional to their reconstruction loss\n",
    "            - Set new values of W_dec and W_enc to be these (centered and normalized) vectors, at each dead neuron\n",
    "            - Set b_enc to be zero, at each dead neuron\n",
    "        \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.test_sae_init(SAE)\n",
    "tests.test_sae_W_dec_normalized(SAE)\n",
    "tests.test_sae_generate_batch(SAE)\n",
    "tests.test_sae_forward(SAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_hidden = d_in = 2\n",
    "n_features = d_sae = 5\n",
    "n_inst = 8\n",
    "\n",
    "cfg = Config(n_inst=n_inst, n_features=n_features, d_hidden=d_hidden)\n",
    "\n",
    "model = Model(cfg=cfg, device=device)\n",
    "model.optimize(steps=10_000)\n",
    "\n",
    "sae = SAE(cfg=SAEConfig(n_inst=n_inst, d_in=d_in, d_sae=d_sae), model=model)\n",
    "\n",
    "h = sae.generate_batch(500)\n",
    "utils.plot_features_in_2d(model.W, title=\"Base model\")\n",
    "utils.plot_features_in_2d(\n",
    "    einops.rearrange(h, \"batch inst d_in -> inst d_in batch\"),\n",
    "    title=\"Hidden state representation of a random batch of data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_log = sae.optimize(steps=25_000)\n",
    "\n",
    "utils.animate_features_in_2d(\n",
    "    {\n",
    "        \"Encoder weights\": t.stack(data_log[\"W_enc\"]),\n",
    "        \"Decoder weights\": t.stack(data_log[\"W_dec\"]).transpose(-1, -2),\n",
    "    },\n",
    "    steps=data_log[\"steps\"],\n",
    "    filename=\"animation-training.html\",\n",
    "    title=\"SAE on toy model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.frac_active_line_plot(\n",
    "    frac_active=t.stack(data_log[\"frac_active\"]),\n",
    "    title=\"Probability of sae features being active during training\",\n",
    "    avg_window=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.test_resample_simple(SAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae = SAE(cfg=SAEConfig(n_inst=n_inst, d_in=d_in, d_sae=d_sae), model=model)\n",
    "\n",
    "data_log = sae.optimize(steps=25_000, resample_method=\"simple\")\n",
    "\n",
    "utils.animate_features_in_2d(\n",
    "    {\n",
    "        \"Encoder weights\": t.stack(data_log[\"W_enc\"]),\n",
    "        \"Decoder weights\": t.stack(data_log[\"W_dec\"]).transpose(-1, -2),\n",
    "    },\n",
    "    steps=data_log[\"steps\"],\n",
    "    filename=\"animation-resampling.html\",\n",
    "    title=\"SAE on toy model with simple resampling\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with t.inference_mode():\n",
    "    h_r = sae(h)[-1]\n",
    "\n",
    "utils.animate_features_in_2d(\n",
    "    {\n",
    "        \"h\": einops.rearrange(h, \"batch inst d_in -> inst d_in batch\"),\n",
    "        \"h<sub>r</sub>\": einops.rearrange(h_r, \"batch inst d_in -> inst d_in batch\"),\n",
    "    },\n",
    "    filename=\"animation-reconstructions.html\",\n",
    "    title=\"Hidden state vs reconstructions\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae = SAE(cfg=SAEConfig(n_inst=n_inst, d_in=d_in, d_sae=d_sae+5), model=model)\n",
    "\n",
    "data_log = sae.optimize(steps=25_000, resample_method=\"simple\")\n",
    "\n",
    "utils.animate_features_in_2d(\n",
    "    {\n",
    "        \"Encoder weights\": t.stack(data_log[\"W_enc\"]),\n",
    "        \"Decoder weights\": t.stack(data_log[\"W_dec\"]).transpose(-1, -2),\n",
    "    },\n",
    "    steps=data_log[\"steps\"],\n",
    "    filename=\"animation-resampling.html\",\n",
    "    title=\"SAE on toy model with simple resampling\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config(n_inst=8, n_features=4, d_hidden=2)\n",
    "\n",
    "model = Model(cfg=cfg, device=device, feature_probability=0.025)\n",
    "\n",
    "# Replace the model's weights with a custom-chosen non-uniform set of features\n",
    "angles = 2 * t.pi * t.tensor([0.0, 0.25, 0.55, 0.70])\n",
    "angles = angles + t.rand((cfg.n_inst, 1))\n",
    "model.W.data = t.stack([t.cos(angles), t.sin(angles)], dim=1).to(device)\n",
    "\n",
    "utils.plot_features_in_2d(\n",
    "    model.W,\n",
    "    title=f\"Superposition: {cfg.n_features} features in 2D space (non-uniform)\",\n",
    "    subplot_titles=[f\"Instance #{i}\" for i in range(1, 1 + cfg.n_inst)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae = SAE(cfg=SAEConfig(n_inst=n_inst, d_in=d_in, d_sae=d_sae), model=model)\n",
    "\n",
    "data_log = sae.optimize(steps=25_000, resample_method=\"simple\")\n",
    "\n",
    "utils.animate_features_in_2d(\n",
    "    {\n",
    "        \"Encoder weights\": t.stack(data_log[\"W_enc\"]),\n",
    "        \"Decoder weights\": t.stack(data_log[\"W_dec\"]).transpose(-1, -2),\n",
    "    },\n",
    "    steps=data_log[\"steps\"],\n",
    "    filename=\"animation-resampling.html\",\n",
    "    title=\"SAE on toy model with simple resampling\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
