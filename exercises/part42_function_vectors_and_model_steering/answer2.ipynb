{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import circuitsvis as cv\n",
    "import einops\n",
    "import numpy as np\n",
    "import torch as t\n",
    "from IPython.display import display\n",
    "from jaxtyping import Float\n",
    "from nnsight import CONFIG, LanguageModel\n",
    "from rich import print as rprint\n",
    "from rich.table import Table\n",
    "from torch import Tensor\n",
    "import string as s\n",
    "\n",
    "# Hide bunch of info logging messages from nnsight\n",
    "import logging, warnings\n",
    "logging.disable(sys.maxsize)\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='huggingface_hub.utils._token')\n",
    "\n",
    "device = t.device('mps' if t.backends.mps.is_available() else 'cuda' if t.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "t.set_grad_enabled(False)\n",
    "\n",
    "# Make sure exercises are in the path\n",
    "chapter = r\"chapter1_transformer_interp\"\n",
    "exercises_dir = Path(f\"{os.getcwd().split(chapter)[0]}/{chapter}/exercises\").resolve()\n",
    "section_dir = exercises_dir / \"part42_function_vectors_and_model_steering\"\n",
    "if str(exercises_dir) not in sys.path: sys.path.append(str(exercises_dir))\n",
    "\n",
    "from plotly_utils import imshow\n",
    "import part42_function_vectors_and_model_steering.solutions as solutions\n",
    "import part42_function_vectors_and_model_steering.tests as tests\n",
    "\n",
    "MAIN = __name__ == '__main__'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of heads: 16\n",
      "Number of layers: 28\n",
      "Model dimension: 4096\n",
      "Head dimension: 256\n",
      "\n",
      "Entire config:  GPTJConfig {\n",
      "  \"_name_or_path\": \"EleutherAI/gpt-j-6b\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPTJForCausalLM\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.0,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gptj\",\n",
      "  \"n_embd\": 4096,\n",
      "  \"n_head\": 16,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 28,\n",
      "  \"n_positions\": 2048,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rotary\": true,\n",
      "  \"rotary_dim\": 64,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50,\n",
      "      \"temperature\": 1.0\n",
      "    }\n",
      "  },\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_class\": \"GPT2Tokenizer\",\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.44.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50400\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/arena-env/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = LanguageModel('EleutherAI/gpt-j-6b', device_map='auto', torch_dtype=t.bfloat16)\n",
    "tokenizer = model.tokenizer\n",
    "\n",
    "N_HEADS = model.config.n_head\n",
    "N_LAYERS = model.config.n_layer\n",
    "D_MODEL = model.config.n_embd\n",
    "D_HEAD = D_MODEL // N_HEADS\n",
    "\n",
    "print(f\"Number of heads: {N_HEADS}\")\n",
    "print(f\"Number of layers: {N_LAYERS}\")\n",
    "print(f\"Model dimension: {D_MODEL}\")\n",
    "print(f\"Head dimension: {D_HEAD}\\n\")\n",
    "\n",
    "print(\"Entire config: \", model.config)\n",
    "\n",
    "REMOTE = True\n",
    "# If you want to set REMOTE = True then you'll need an API key. Please join the NDIF community\n",
    "# Discord (https://nnsight.net/status/) and request one from there, then uncomment and run the\n",
    "# following code:\n",
    "CONFIG.set_default_api_key(\"7592caadcba94ba2a9e3e008a8a3f6a2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTJForCausalLM(\n",
      "  (transformer): GPTJModel(\n",
      "    (wte): Embedding(50400, 4096)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-27): 28 x GPTJBlock(\n",
      "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPTJAttention(\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "        )\n",
      "        (mlp): GPTJMLP(\n",
      "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
      "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=50400, bias=True)\n",
      "  (generator): WrapperModule()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Downloading result: 100%|██████████| 928/928 [00:00<00:00, 1.08MB/s]\n"
     ]
    }
   ],
   "source": [
    "with model.trace(\"Hello,\", remote=REMOTE):\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['old', 'young'], ['top', 'bottom'], ['awake', 'asleep'], ['future', 'past'], ['appear', 'disappear'], ['early', 'late'], ['empty', 'full'], ['innocent', 'guilty'], ['ancient', 'modern'], ['arrive', 'depart']]\n"
     ]
    }
   ],
   "source": [
    "# Load the word pairs from the text file\n",
    "with open(section_dir / \"data\" / \"antonym_pairs.txt\", \"r\") as f:\n",
    "    ANTONYM_PAIRS = [line.split() for line in f.readlines()]\n",
    "\n",
    "print(ANTONYM_PAIRS[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuple-representation of the sequence:\n",
      "(hot, cold), (yes, no), (in, out), up ->\n",
      "\n",
      "Actual prompt, which will be fed into the model:\n",
      "Q: hot\n",
      "A: cold\n",
      "\n",
      "Q: yes\n",
      "A: no\n",
      "\n",
      "Q: in\n",
      "A: out\n",
      "\n",
      "Q: up\n",
      "A:\n"
     ]
    }
   ],
   "source": [
    "class ICLSequence:\n",
    "    '''\n",
    "    Class to store a single antonym sequence.\n",
    "\n",
    "    Uses the default template \"Q: {x}\\nA: {y}\" (with separate pairs split by \"\\n\\n\").\n",
    "    '''\n",
    "    def __init__(self, word_pairs: list[tuple[str, str]]):\n",
    "        self.word_pairs = word_pairs\n",
    "        self.x, self.y = zip(*word_pairs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.word_pairs)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return self.word_pairs[idx]\n",
    "\n",
    "    def prompt(self):\n",
    "        '''Returns the prompt, which contains all but the second element in the last word pair.'''\n",
    "        p = \"\\n\\n\".join([f\"Q: {x}\\nA: {y}\" for x, y in self.word_pairs])\n",
    "        return p[:-len(self.completion())]\n",
    "\n",
    "    def completion(self):\n",
    "        '''Returns the second element in the last word pair (with padded space).'''\n",
    "        return \" \" + self.y[-1]\n",
    "\n",
    "    def __str__(self):\n",
    "        '''Prints a readable string representation of the prompt & completion (indep of template).'''\n",
    "        return f\"{', '.join([f'({x}, {y})' for x, y in self[:-1]])}, {self.x[-1]} ->\".strip(\", \")\n",
    "\n",
    "\n",
    "word_list = [[\"hot\", \"cold\"], [\"yes\", \"no\"], [\"in\", \"out\"], [\"up\", \"down\"]]\n",
    "seq = ICLSequence(word_list)\n",
    "\n",
    "print(\"Tuple-representation of the sequence:\")\n",
    "print(seq)\n",
    "print(\"\\nActual prompt, which will be fed into the model:\")\n",
    "print(seq.prompt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICLDataset:\n",
    "    '''\n",
    "    Dataset to create antonym pair prompts, in ICL task format. We use random seeds for consistency\n",
    "    between the corrupted and clean datasets.\n",
    "\n",
    "    Inputs:\n",
    "        word_pairs:\n",
    "            list of ICL task, e.g. [[\"old\", \"young\"], [\"top\", \"bottom\"], ...] for the antonym task\n",
    "        size:\n",
    "            number of prompts to generate\n",
    "        n_prepended:\n",
    "            number of antonym pairs before the single-word ICL task\n",
    "        bidirectional:\n",
    "            if True, then we also consider the reversed antonym pairs\n",
    "        corrupted:\n",
    "            if True, then the second word in each pair is replaced with a random word\n",
    "        seed:\n",
    "            random seed, for consistency & reproducibility\n",
    "    '''\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        word_pairs: list[tuple[str, str]],\n",
    "        size: int,\n",
    "        n_prepended: int,\n",
    "        bidirectional: bool = True,\n",
    "        seed: int = 0,\n",
    "        corrupted: bool = False,\n",
    "    ):\n",
    "        assert n_prepended+1 <= len(word_pairs), \"Not enough antonym pairs in dataset to create prompt.\"\n",
    "\n",
    "        self.word_pairs = word_pairs\n",
    "        self.word_list = [word for word_pair in word_pairs for word in word_pair]\n",
    "        self.size = size\n",
    "        self.n_prepended = n_prepended\n",
    "        self.bidirectional = bidirectional\n",
    "        self.corrupted = corrupted\n",
    "        self.seed = seed\n",
    "\n",
    "        self.seqs = []\n",
    "        self.prompts = []\n",
    "        self.completions = []\n",
    "\n",
    "        # Generate the dataset (by choosing random antonym pairs, and constructing `ICLSequence` objects)\n",
    "        for n in range(size):\n",
    "            np.random.seed(seed + n)\n",
    "            random_pairs = np.random.choice(len(self.word_pairs), n_prepended+1, replace=False)\n",
    "            random_orders = np.random.choice([1, -1], n_prepended+1)\n",
    "            if not(bidirectional): random_orders[:] = 1\n",
    "            word_pairs = [self.word_pairs[pair][::order] for pair, order in zip(random_pairs, random_orders)]\n",
    "            if corrupted:\n",
    "                for i in range(len(word_pairs) - 1):\n",
    "                    word_pairs[i][1] = np.random.choice(self.word_list)\n",
    "            seq = ICLSequence(word_pairs)\n",
    "\n",
    "            self.seqs.append(seq)\n",
    "            self.prompts.append(seq.prompt())\n",
    "            self.completions.append(seq.completion())\n",
    "\n",
    "    def create_corrupted_dataset(self):\n",
    "        '''Creates a corrupted version of the dataset (with same random seed).'''\n",
    "        return ICLDataset(self.word_pairs, self.size, self.n_prepended, self.bidirectional, corrupted=True, seed=self.seed)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return self.seqs[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Prompt                                               </span>┃<span style=\"font-weight: bold\"> Correct completion </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ (right, left), (maximum, minimum), melt -&gt;           │ ' freeze'          │\n",
       "│ (minimum, maximum), (old, new), punishment -&gt;        │ ' reward'          │\n",
       "│ (arrogant, humble), (blunt, sharp), compulsory -&gt;    │ ' voluntary'       │\n",
       "│ (inside, outside), (freeze, melt), full -&gt;           │ ' empty'           │\n",
       "│ (reject, accept), (awake, asleep), dusk -&gt;           │ ' dawn'            │\n",
       "│ (invisible, visible), (punishment, reward), heavy -&gt; │ ' light'           │\n",
       "│ (victory, defeat), (forward, backward), young -&gt;     │ ' old'             │\n",
       "│ (up, down), (compulsory, voluntary), right -&gt;        │ ' wrong'           │\n",
       "│ (open, closed), (domestic, foreign), brave -&gt;        │ ' cowardly'        │\n",
       "│ (under, over), (past, future), increase -&gt;           │ ' decrease'        │\n",
       "└──────────────────────────────────────────────────────┴────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mPrompt                                              \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mCorrect completion\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ (right, left), (maximum, minimum), melt ->           │ ' freeze'          │\n",
       "│ (minimum, maximum), (old, new), punishment ->        │ ' reward'          │\n",
       "│ (arrogant, humble), (blunt, sharp), compulsory ->    │ ' voluntary'       │\n",
       "│ (inside, outside), (freeze, melt), full ->           │ ' empty'           │\n",
       "│ (reject, accept), (awake, asleep), dusk ->           │ ' dawn'            │\n",
       "│ (invisible, visible), (punishment, reward), heavy -> │ ' light'           │\n",
       "│ (victory, defeat), (forward, backward), young ->     │ ' old'             │\n",
       "│ (up, down), (compulsory, voluntary), right ->        │ ' wrong'           │\n",
       "│ (open, closed), (domestic, foreign), brave ->        │ ' cowardly'        │\n",
       "│ (under, over), (past, future), increase ->           │ ' decrease'        │\n",
       "└──────────────────────────────────────────────────────┴────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = ICLDataset(ANTONYM_PAIRS, size=10, n_prepended=2, corrupted=False)\n",
    "\n",
    "table = Table(\"Prompt\", \"Correct completion\")\n",
    "for seq, completion in zip(dataset.seqs, dataset.completions):\n",
    "    table.add_row(str(seq), repr(completion))\n",
    "\n",
    "rprint(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Prompt                                            </span>┃<span style=\"font-weight: bold\"> Correct completion </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ (right, private), (maximum, destroy), melt -&gt;     │ ' freeze'          │\n",
       "│ (minimum, increase), (old, sharp), punishment -&gt;  │ ' reward'          │\n",
       "│ (arrogant, humble), (blunt, deep), compulsory -&gt;  │ ' voluntary'       │\n",
       "│ (inside, voluntary), (freeze, exterior), full -&gt;  │ ' empty'           │\n",
       "│ (reject, profit), (awake, start), dusk -&gt;         │ ' dawn'            │\n",
       "│ (invisible, birth), (punishment, spend), heavy -&gt; │ ' light'           │\n",
       "│ (victory, rich), (forward, honest), young -&gt;      │ ' old'             │\n",
       "│ (up, lie), (compulsory, short), right -&gt;          │ ' wrong'           │\n",
       "│ (open, soft), (domestic, anxious), brave -&gt;       │ ' cowardly'        │\n",
       "│ (under, melt), (past, young), increase -&gt;         │ ' decrease'        │\n",
       "└───────────────────────────────────────────────────┴────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mPrompt                                           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mCorrect completion\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ (right, private), (maximum, destroy), melt ->     │ ' freeze'          │\n",
       "│ (minimum, increase), (old, sharp), punishment ->  │ ' reward'          │\n",
       "│ (arrogant, humble), (blunt, deep), compulsory ->  │ ' voluntary'       │\n",
       "│ (inside, voluntary), (freeze, exterior), full ->  │ ' empty'           │\n",
       "│ (reject, profit), (awake, start), dusk ->         │ ' dawn'            │\n",
       "│ (invisible, birth), (punishment, spend), heavy -> │ ' light'           │\n",
       "│ (victory, rich), (forward, honest), young ->      │ ' old'             │\n",
       "│ (up, lie), (compulsory, short), right ->          │ ' wrong'           │\n",
       "│ (open, soft), (domestic, anxious), brave ->       │ ' cowardly'        │\n",
       "│ (under, melt), (past, young), increase ->         │ ' decrease'        │\n",
       "└───────────────────────────────────────────────────┴────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = ICLDataset(ANTONYM_PAIRS, size=10, n_prepended=2, corrupted=True)\n",
    "\n",
    "table = Table(\"Prompt\", \"Correct completion\")\n",
    "for seq, completions in zip(dataset.seqs, dataset.completions):\n",
    "    table.add_row(str(seq), repr(completions))\n",
    "\n",
    "rprint(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 33\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(token_idx\u001b[38;5;241m.\u001b[39mvalue)\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m, h\u001b[38;5;241m.\u001b[39mvalue\n\u001b[0;32m---> 33\u001b[0m \u001b[43mtests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_calculate_h\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcalculate_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/My/code/MI/ARENA_3.0/chapter1_transformer_interp/exercises/part42_function_vectors_and_model_steering/tests.py:119\u001b[0m, in \u001b[0;36mtest_calculate_h\u001b[0;34m(calculate_h, model, solution)\u001b[0m\n\u001b[1;32m    117\u001b[0m word_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(string\u001b[38;5;241m.\u001b[39mascii_lowercase, string\u001b[38;5;241m.\u001b[39mascii_uppercase))\n\u001b[1;32m    118\u001b[0m dataset \u001b[38;5;241m=\u001b[39m ICLDataset(word_pairs, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_prepended\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, bidirectional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 119\u001b[0m model_completions, h \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_h\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Check model completions\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mcompletions \u001b[38;5;241m==\u001b[39m [\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m L\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m K\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m K\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    128\u001b[0m ], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected error in the test function - please report this in #errara on Slack.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m, in \u001b[0;36mcalculate_h\u001b[0;34m(model, dataset, layer)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mAverages over the model's hidden representations on each of the prompts in `dataset` at layer `layer`, to produce\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03ma single vector `h`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m        average hidden state tensor at final sequence position, of shape (d_model,)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 21\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mREMOTE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlm_head\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/arena-env/lib/python3.11/site-packages/nnsight/contexts/Tracer.py:102\u001b[0m, in \u001b[0;36mTracer.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoker\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39m_envoy\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__exit__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexc_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_tb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/arena-env/lib/python3.11/site-packages/nnsight/contexts/GraphBasedContext.py:217\u001b[0m, in \u001b[0;36mGraphBasedContext.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_val\n\u001b[0;32m--> 217\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/arena-env/lib/python3.11/site-packages/nnsight/contexts/backends/RemoteBackend.py:107\u001b[0m, in \u001b[0;36mRemoteBackend.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    104\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(obj)\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m# Do blocking request.\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocking_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/arena-env/lib/python3.11/site-packages/nnsight/contexts/backends/RemoteBackend.py:273\u001b[0m, in \u001b[0;36mRemoteBackend.blocking_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# Loop until\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m--> 273\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_response(\u001b[43msio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mstatus\n\u001b[1;32m    274\u001b[0m         \u001b[38;5;241m==\u001b[39m ResponseModel\u001b[38;5;241m.\u001b[39mJobStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[1;32m    275\u001b[0m     ):\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/arena-env/lib/python3.11/site-packages/socketio/simple_client.py:175\u001b[0m, in \u001b[0;36mSimpleClient.receive\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnected:\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DisconnectedError()\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_event\u001b[38;5;241m.\u001b[39mclear()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/arena-env/lib/python3.11/threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    627\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/anaconda3/envs/arena-env/lib/python3.11/threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def calculate_h(model: LanguageModel, dataset: ICLDataset, layer: int = -1) -> tuple[list[str], Tensor]:\n",
    "    '''\n",
    "    Averages over the model's hidden representations on each of the prompts in `dataset` at layer `layer`, to produce\n",
    "    a single vector `h`.\n",
    "\n",
    "    Inputs:\n",
    "        model: LanguageModel\n",
    "            the transformer you're doing this computation with\n",
    "        dataset: ICLDataset\n",
    "            the dataset whose prompts `dataset.prompts` you're extracting the activations from (at the last seq pos)\n",
    "        layer: int\n",
    "            the layer you're extracting activations from\n",
    "\n",
    "    Returns:\n",
    "        completions: list[str]\n",
    "            list of the model's next-token predictions (i.e. the strings the model predicts to follow the last token)\n",
    "        h: Tensor\n",
    "            average hidden state tensor at final sequence position, of shape (d_model,)\n",
    "    '''\n",
    "    try:\n",
    "        with model.trace(dataset.prompts, remote=REMOTE, scan=True, validate=True):\n",
    "            logits = model.lm_head.output[:, -1, :]\n",
    "            token_idx = logits.argmax(dim = -1).save()\n",
    "            h = model.transformer.h[layer].output[0][:,-1,:].mean(dim = 0).save()\n",
    "    except Exception as e:\n",
    "        print(f\"Informative error message:\\n  {e.__class__.__name__}: {e}\")\n",
    "\n",
    "    str = model.tokenizer.batch_decode(token_idx.value)\n",
    "\n",
    "    return str, h.value\n",
    "\n",
    "\n",
    "tests.test_calculate_h(calculate_h, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_model_completions_on_antonyms(\n",
    "    model: LanguageModel,\n",
    "    dataset: ICLDataset,\n",
    "    completions: list[str],\n",
    "    num_to_display: int = 20,\n",
    ") -> None:\n",
    "    table = Table(\"Prompt (tuple representation)\", \"Model's completion\\n(green=correct)\", \"Correct completion\", title=\"Model's antonym completions\")\n",
    "\n",
    "    for i in range(min(len(completions), num_to_display)):\n",
    "\n",
    "        # Get model's completion, and correct completion\n",
    "        completion = completions[i]\n",
    "        correct_completion = dataset.completions[i]\n",
    "        correct_completion_first_token = model.tokenizer.tokenize(correct_completion)[0].replace('Ġ', ' ')\n",
    "        seq = dataset.seqs[i]\n",
    "\n",
    "        # Color code the completion based on whether it's correct\n",
    "        is_correct = (completion == correct_completion_first_token)\n",
    "        completion = f\"[b green]{repr(completion)}[/]\" if is_correct else repr(completion)\n",
    "\n",
    "        table.add_row(str(seq), completion, repr(correct_completion))\n",
    "\n",
    "    rprint(table)\n",
    "\n",
    "\n",
    "# Get uncorrupted dataset\n",
    "dataset = ICLDataset(ANTONYM_PAIRS, size=20, n_prepended=2)\n",
    "\n",
    "# Getting it from layer 12, as in the description in section 2.1 of paper\n",
    "model_completions, h = calculate_h(model, dataset, layer=12)\n",
    "\n",
    "# Displaying the output\n",
    "display_model_completions_on_antonyms(model, dataset, model_completions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intervene_with_h(\n",
    "    model: LanguageModel,\n",
    "    zero_shot_dataset: ICLDataset,\n",
    "    h: Tensor,\n",
    "    layer: int,\n",
    ") -> tuple[list[str], list[str]]:\n",
    "    '''\n",
    "    Extracts the vector `h` using previously defined function, and intervenes by adding `h` to the\n",
    "    residual stream of a set of generated zero-shot prompts.\n",
    "\n",
    "    Inputs:\n",
    "        model: LanguageModel\n",
    "            the transformer you're doing this computation with\n",
    "        zero_shot_dataset: ICLDataset\n",
    "            the dataset of zero-shot prompts which we'll intervene on, using the `h`-vector\n",
    "        h: Tensor\n",
    "            the `h`-vector we'll be adding to the residual stream\n",
    "        layer: int\n",
    "            the layer we'll be extracting the `h`-vector from\n",
    "\n",
    "    Returns:\n",
    "        completions_zero_shot: list[str]\n",
    "            list of string completions for the zero-shot prompts, without intervention\n",
    "        completions_intervention: list[str]\n",
    "            list of string completions for the zero-shot prompts, with h-intervention\n",
    "    '''\n",
    "    with model.trace(remote=REMOTE) as tracer:\n",
    "        with tracer.invoke(zero_shot_dataset.prompts):\n",
    "            clean_logits = model.lm_head.output[:, -1, :]\n",
    "            clean_index = clean_logits.argmax(dim = -1).save()\n",
    "        with tracer.invoke(zero_shot_dataset.prompts):\n",
    "            hidden_states = model.transformer.h[layer].output[0]\n",
    "            hidden_states[:,-1,:] += h\n",
    "            intervention_logits = model.lm_head.output[:, -1, :]\n",
    "            intervention_index = intervention_logits.argmax(dim = -1).save()\n",
    "    \n",
    "    completions_zero_shot = model.tokenizer.batch_decode(clean_index.value)\n",
    "    completions_intervention = model.tokenizer.batch_decode(intervention_index.value)\n",
    "\n",
    "    return completions_zero_shot, completions_intervention\n",
    "\n",
    "\n",
    "tests.test_intervene_with_h(intervene_with_h, model, h, ANTONYM_PAIRS, REMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 12\n",
    "dataset = ICLDataset(ANTONYM_PAIRS, size=20, n_prepended=3, seed=0)\n",
    "zero_shot_dataset = ICLDataset(ANTONYM_PAIRS, size=20, n_prepended=0, seed=1)\n",
    "\n",
    "# Run previous function to get h-vector\n",
    "h = calculate_h(model, dataset, layer=layer)[1]\n",
    "\n",
    "# Run new function to intervene with h-vector\n",
    "completions_zero_shot, completions_intervention = intervene_with_h(model, zero_shot_dataset, h, layer=layer)\n",
    "\n",
    "print(\"Zero-shot completions: \", completions_zero_shot)\n",
    "print(\"Completions with intervention: \", completions_intervention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_model_completions_on_h_intervention(\n",
    "    dataset: ICLDataset,\n",
    "    completions: list[str],\n",
    "    completions_intervention: list[str],\n",
    "    num_to_display: int = 20,\n",
    ") -> None:\n",
    "    table = Table(\"Prompt\", \"Model's completion\\n(no intervention)\", \"Model's completion\\n(intervention)\", \"Correct completion\", title=\"Model's antonym completions\")\n",
    "\n",
    "    for i in range(min(len(completions), num_to_display)):\n",
    "\n",
    "        completion_ni = completions[i]\n",
    "        completion_i = completions_intervention[i]\n",
    "        correct_completion = dataset.completions[i]\n",
    "        correct_completion_first_token = tokenizer.tokenize(correct_completion)[0].replace('Ġ', ' ')\n",
    "        seq = dataset.seqs[i]\n",
    "\n",
    "        # Color code the completion based on whether it's correct\n",
    "        is_correct = (completion_i == correct_completion_first_token)\n",
    "        completion_i = f\"[b green]{repr(completion_i)}[/]\" if is_correct else repr(completion_i)\n",
    "\n",
    "        is_correct = (completion_ni == correct_completion_first_token)\n",
    "        completion_ni = f\"[b green]{repr(completion_ni)}[/]\" if is_correct else repr(completion_ni)\n",
    "\n",
    "        table.add_row(str(seq), completion_ni, completion_i, repr(correct_completion))\n",
    "\n",
    "    rprint(table)\n",
    "\n",
    "\n",
    "display_model_completions_on_h_intervention(zero_shot_dataset, completions_zero_shot, completions_intervention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_h_and_intervene(\n",
    "    model: LanguageModel,\n",
    "    dataset: ICLDataset,\n",
    "    zero_shot_dataset: ICLDataset,\n",
    "    layer: int,\n",
    ") -> tuple[list[str], list[str]]:\n",
    "    '''\n",
    "    Extracts the vector `h`, intervenes by adding `h` to the residual stream of a set of generated zero-shot prompts,\n",
    "    all within the same forward pass. Returns the completions from this intervention.\n",
    "\n",
    "    Inputs:\n",
    "        model: LanguageModel\n",
    "            the model we're using to generate completions\n",
    "        dataset: ICLDataset\n",
    "            the dataset of clean prompts from which we'll extract the `h`-vector\n",
    "        zero_shot_dataset: ICLDataset\n",
    "            the dataset of zero-shot prompts which we'll intervene on, using the `h`-vector\n",
    "        layer: int\n",
    "            the layer we'll be extracting the `h`-vector from\n",
    "\n",
    "    Returns:\n",
    "        completions_zero_shot: list[str]\n",
    "            list of string completions for the zero-shot prompts, without intervention\n",
    "        completions_intervention: list[str]\n",
    "            list of string completions for the zero-shot prompts, with h-intervention\n",
    "    '''\n",
    "    with model.trace(remote=REMOTE) as tracer:\n",
    "        with tracer.invoke(dataset.prompts):\n",
    "            h = model.transformer.h[layer].output[0][:,-1,:].mean(dim = 0)\n",
    "        with tracer.invoke(zero_shot_dataset.prompts):\n",
    "            clean_logits = model.lm_head.output[:, -1, :]\n",
    "            clean_index = clean_logits.argmax(dim = -1).save()\n",
    "        with tracer.invoke(zero_shot_dataset.prompts):\n",
    "            hidden_states = model.transformer.h[layer].output[0]\n",
    "            hidden_states[:,-1,:] += h\n",
    "            intervention_logits = model.lm_head.output[:, -1, :]\n",
    "            intervention_index = intervention_logits.argmax(dim = -1).save()\n",
    "\n",
    "    completions_zero_shot = model.tokenizer.batch_decode(clean_index.value)\n",
    "    completions_intervention = model.tokenizer.batch_decode(intervention_index.value)\n",
    "\n",
    "    return completions_zero_shot, completions_intervention\n",
    "\n",
    "\n",
    "dataset = ICLDataset(ANTONYM_PAIRS, size=20, n_prepended=3, seed=0)\n",
    "zero_shot_dataset = ICLDataset(ANTONYM_PAIRS, size=20, n_prepended=0, seed=1)\n",
    "\n",
    "completions_zero_shot, completions_intervention = calculate_h_and_intervene(model, dataset, zero_shot_dataset, layer=layer)\n",
    "\n",
    "display_model_completions_on_h_intervention(zero_shot_dataset, completions_zero_shot, completions_intervention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_h_and_intervene_logprobs(\n",
    "    model: LanguageModel,\n",
    "    dataset: ICLDataset,\n",
    "    zero_shot_dataset: ICLDataset,\n",
    "    layer: int,\n",
    ") -> tuple[list[float], list[float]]:\n",
    "    '''\n",
    "    Extracts the vector `h`, intervenes by adding `h` to the residual stream of a set of generated zero-shot prompts,\n",
    "    all within the same forward pass. Returns the logprobs on correct tokens from this intervention.\n",
    "\n",
    "    Inputs:\n",
    "        model: LanguageModel\n",
    "            the model we're using to generate completions\n",
    "        dataset: ICLDataset\n",
    "            the dataset of clean prompts from which we'll extract the `h`-vector\n",
    "        zero_shot_dataset: ICLDataset\n",
    "            the dataset of zero-shot prompts which we'll intervene on, using the `h`-vector\n",
    "        layer: int\n",
    "            the layer we'll be extracting the `h`-vector from\n",
    "\n",
    "    Returns:\n",
    "        correct_logprobs: list[float]\n",
    "            list of correct-token logprobs for the zero-shot prompts, without intervention\n",
    "        correct_logprobs_intervention: list[float]\n",
    "            list of correct-token logprobs for the zero-shot prompts, with h-intervention\n",
    "    '''\n",
    "    target_index = [tok[0] for tok in model.tokenizer(zero_shot_dataset.completions)[\"input_ids\"]]\n",
    "    with model.trace(remote=REMOTE) as tracer:\n",
    "        with tracer.invoke(dataset.prompts):\n",
    "            h = model.transformer.h[layer].output[0][:,-1,:].mean(dim = 0)\n",
    "        with tracer.invoke(zero_shot_dataset.prompts):\n",
    "            clean_logits = model.lm_head.output[:, -1, :]\n",
    "            clean_prob = t.softmax(clean_logits, dim= -1)\n",
    "            clean_prob_target = clean_prob[t.arange(len(zero_shot_dataset.prompts)), target_index].save()\n",
    "        with tracer.invoke(zero_shot_dataset.prompts):\n",
    "            hidden_states = model.transformer.h[layer].output[0]\n",
    "            hidden_states[:,-1,:] += h\n",
    "            intervention_logits = model.lm_head.output[:, -1, :]\n",
    "            intervention_prob = t.softmax(intervention_logits, dim= -1)\n",
    "            intervention_prob_target = intervention_prob[t.arange(len(zero_shot_dataset.prompts)), target_index].save()\n",
    "\n",
    "    return clean_prob_target.value.tolist(), intervention_prob_target.value.tolist()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_model_logprobs_on_h_intervention(\n",
    "    dataset: ICLDataset,\n",
    "    correct_logprobs_zero_shot: list[float],\n",
    "    correct_logprobs_intervention: list[float],\n",
    "    num_to_display: int = 20,\n",
    ") -> None:\n",
    "    table = Table(\n",
    "        \"Zero-shot prompt\", \"Model's logprob\\n(no intervention)\", \"Model's logprob\\n(intervention)\", \"Change in logprob\",\n",
    "        title=\"Model's antonym logprobs, with zero-shot h-intervention\\n(green = intervention improves accuracy)\"\n",
    "    )\n",
    "\n",
    "    for i in range(min(len(correct_logprobs_zero_shot), num_to_display)):\n",
    "\n",
    "        logprob_ni = correct_logprobs_zero_shot[i]\n",
    "        logprob_i = correct_logprobs_intervention[i]\n",
    "        delta_logprob = logprob_i - logprob_ni\n",
    "        zero_shot_prompt = f\"{dataset[i].x[0]:>8} -> {dataset[i].y[0]}\"\n",
    "\n",
    "        # Color code the logprob based on whether it's increased with this intervention\n",
    "        is_improvement = (delta_logprob >= 0)\n",
    "        delta_logprob = f\"[b green]{delta_logprob:+.2f}[/]\" if is_improvement else f\"{delta_logprob:+.2f}\"\n",
    "\n",
    "        table.add_row(zero_shot_prompt, f\"{logprob_ni:.2f}\", f\"{logprob_i:.2f}\", delta_logprob)\n",
    "\n",
    "    rprint(table)\n",
    "\n",
    "\n",
    "dataset = ICLDataset(ANTONYM_PAIRS, size=20, n_prepended=3, seed=0)\n",
    "zero_shot_dataset = ICLDataset(ANTONYM_PAIRS, size=20, n_prepended=0, seed=1)\n",
    "\n",
    "correct_logprobs_zero_shot, correct_logprobs_intervention = calculate_h_and_intervene_logprobs(model, dataset, zero_shot_dataset, layer=layer)\n",
    "\n",
    "display_model_logprobs_on_h_intervention(zero_shot_dataset, correct_logprobs_zero_shot, correct_logprobs_intervention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arena-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
