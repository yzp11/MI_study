{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import circuitsvis as cv\n",
    "import einops\n",
    "import numpy as np\n",
    "import torch as t\n",
    "from IPython.display import display\n",
    "from jaxtyping import Float\n",
    "from nnsight import CONFIG, LanguageModel\n",
    "from rich import print as rprint\n",
    "from rich.table import Table\n",
    "from torch import Tensor\n",
    "import string as s\n",
    "\n",
    "# Hide bunch of info logging messages from nnsight\n",
    "import logging, warnings\n",
    "logging.disable(sys.maxsize)\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='huggingface_hub.utils._token')\n",
    "\n",
    "device = t.device('mps' if t.backends.mps.is_available() else 'cuda' if t.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "t.set_grad_enabled(False)\n",
    "\n",
    "# Make sure exercises are in the path\n",
    "chapter = \"exercises\"\n",
    "exercises_dir = Path(f\"{os.getcwd().split(chapter)[0]}/{chapter}\").resolve()\n",
    "section_dir = exercises_dir / \"part42_function_vectors_and_model_steering\"\n",
    "if str(exercises_dir) not in sys.path: sys.path.append(str(exercises_dir))\n",
    "\n",
    "from plotly_utils import imshow\n",
    "import part42_function_vectors_and_model_steering.solutions as solutions\n",
    "import part42_function_vectors_and_model_steering.tests as tests\n",
    "\n",
    "MAIN = __name__ == '__main__'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LanguageModel('EleutherAI/gpt-j-6b', device_map='auto', torch_dtype=t.bfloat16)\n",
    "tokenizer = model.tokenizer\n",
    "\n",
    "N_HEADS = model.config.n_head\n",
    "N_LAYERS = model.config.n_layer\n",
    "D_MODEL = model.config.n_embd\n",
    "D_HEAD = D_MODEL // N_HEADS\n",
    "\n",
    "print(f\"Number of heads: {N_HEADS}\")\n",
    "print(f\"Number of layers: {N_LAYERS}\")\n",
    "print(f\"Model dimension: {D_MODEL}\")\n",
    "print(f\"Head dimension: {D_HEAD}\\n\")\n",
    "\n",
    "print(\"Entire config: \", model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling tokenizer returns a dictionary, containing input ids & other data.\n",
    "# If returned as a tensor, then by default it will have a batch dimension.\n",
    "print(tokenizer(\"This must be Thursday\", return_tensors=\"pt\"))\n",
    "\n",
    "# Decoding a list of integers, into a concatenated string.\n",
    "print(tokenizer.decode([40, 1239, 714, 651, 262, 8181, 286, 48971, 12545, 13]))\n",
    "\n",
    "# Using batch decode, on both 1D and 2D input.\n",
    "print(tokenizer.batch_decode([4711, 2456, 481, 307, 6626, 510]))\n",
    "print(tokenizer.batch_decode([[1212, 6827, 481, 307, 1978], [2396, 481, 428, 530]]))\n",
    "\n",
    "# Split sentence into tokens (note we see the special Ġ character in place of prepended spaces).\n",
    "print(tokenizer.tokenize(\"This sentence will be tokenized\"))\n",
    "\n",
    "model.tokenizer([\"Hello world\", \"Hello\"], return_tensors=\"pt\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REMOTE = True\n",
    "# If you want to set REMOTE = True then you'll need an API key. Please join the NDIF community\n",
    "# Discord (https://nnsight.net/status/) and request one from there, then uncomment and run the\n",
    "# following code:\n",
    "CONFIG.set_default_api_key(\"7592caadcba94ba2a9e3e008a8a3f6a2\")\n",
    "\n",
    "prompt = 'The Eiffel Tower is in the city of'\n",
    "\n",
    "with model.trace(prompt, remote=REMOTE):\n",
    "    # Save the model's hidden states\n",
    "    print(model.transformer.h[-1])\n",
    "    hidden_states = model.transformer.h[-1].output[0].save()\n",
    "\n",
    "    # Save the model's logit output\n",
    "    logits = model.lm_head.output[0, -1].save()\n",
    "\n",
    "# Get the model's logit output, and it's next token prediction\n",
    "print(f\"logits.shape = {logits.value.shape} = (vocab_size,)\")\n",
    "print(\"Predicted token ID =\", predicted_token_id := logits.value.argmax().item())\n",
    "print(f\"Predicted token = {tokenizer.decode(predicted_token_id)!r}\")\n",
    "\n",
    "# Print the shape of the model's residual stream\n",
    "print(f\"resid.shape = {hidden_states.value.shape} = (batch_size, seq_len, d_model)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = len(model.tokenizer.encode(prompt))\n",
    "\n",
    "try:\n",
    "    with model.trace(prompt, remote=REMOTE):\n",
    "        original_output = model.transformer.h[-1].output[0].clone().save()\n",
    "        model.transformer.h[-1].output[0][:, seq_len] = 0\n",
    "        modified_output = model.transformer.h[-1].output[0].save()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Uninformative error message:\\n  {e.__class__.__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with model.trace(prompt, remote=REMOTE, scan=True, validate=True):\n",
    "        original_output = model.transformer.h[-1].output[0].clone().save()\n",
    "        print(f\"{model.transformer.h[-1].output.shape=}\\n\")\n",
    "        model.transformer.h[-1].output[0][:, seq_len-1] = 0\n",
    "        modified_output = model.transformer.h[-1].output[0].save()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Informative error message:\\n  {e.__class__.__name__}: {e}\")\n",
    "\n",
    "print(original_output.value[0,-1,:], modified_output[0,-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_output.value[0,-1,:], modified_output[0,-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.tokenize(prompt)\n",
    "try:\n",
    "    with model.trace(prompt, remote=REMOTE, scan=True, validate=True):\n",
    "        attention = model.transformer.h[0].attn.attn_dropout.input.save()\n",
    "except Exception as e:\n",
    "    print(f\"Informative error message:\\n  {e.__class__.__name__}: {e}\")\n",
    "\n",
    "tokens = [s.replace('Ġ', ' ') for s in tokens]\n",
    "attention = attention.value[0]\n",
    "print(attention.shape)\n",
    "\n",
    "cv.attention.attention_patterns(\n",
    "    tokens=tokens,\n",
    "    attention=attention,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arena-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
